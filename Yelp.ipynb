{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# read the entire file into a python array\n",
    "filename = \"yelp_academic_dataset_checkin.json\"\n",
    "with open(filename, 'rb') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "# remove the trailing \"\\n\" from each line\n",
    "data = map(lambda x: x.rstrip(), data)\n",
    "\n",
    "# each element of 'data' is an individual JSON object.\n",
    "# i want to convert it into an *array* of JSON objects\n",
    "# which, in and of itself, is one large JSON object\n",
    "# basically... add square brackets to the beginning\n",
    "# and end, and have all the individual business JSON objects\n",
    "# separated by a comma\n",
    "data_json_str = \"[\" + ','.join(data) + \"]\"\n",
    "# now, load it into pandas\n",
    "data_df = pd.read_json(data_json_str)\n",
    "data_df = data_df[:20000]\n",
    "# Get time distribution in one week and a day\n",
    "week_time_distribution = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "day_time_distribution = [str(i) for i in range(24)]\n",
    "column_names = week_time_distribution + day_time_distribution\n",
    "column_names.insert(0, \"business_id\")\n",
    "business_attributes = pd.DataFrame(columns = column_names)\n",
    "week_time_distribution = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
    "day_time_distribution = [str(i) for i in range(24)]\n",
    "column_names = week_time_distribution + day_time_distribution\n",
    "column_names.insert(0, \"business_id\")\n",
    "business_attributes = pd.DataFrame(columns = column_names)\n",
    "for index, row in data_df.iterrows():\n",
    "    time_dic = {column_names[i]:0 for i in range(1, len(column_names))}\n",
    "    time_list = row['time']\n",
    "#     print time_dic, column_names[1:]\n",
    "    for time in time_list:\n",
    "        hour = 0\n",
    "        check_ins = 0\n",
    "        date = time[:3]\n",
    "        for i in range(5, len(time)):\n",
    "            if time[i] == ':':\n",
    "                hour = time[4 : i]\n",
    "                count_ins = time[i + 1:]\n",
    "                break\n",
    "        time_dic[str(hour)] = count_ins\n",
    "        time_dic[str(date)] = count_ins\n",
    "    time_dic['business_id'] = row['business_id']\n",
    "    result = [time_dic[name] for name in column_names]\n",
    "#     print time_dic, result\n",
    "    business_attributes.loc[index] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filename = \"yelp_academic_dataset_business.json\"\n",
    "with open(filename, 'rb') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "# remove the trailing \"\\n\" from each line\n",
    "data = map(lambda x: x.rstrip(), data)\n",
    "\n",
    "# each element of 'data' is an individual JSON object.\n",
    "# i want to convert it into an *array* of JSON objects\n",
    "# which, in and of itself, is one large JSON object\n",
    "# basically... add square brackets to the beginning\n",
    "# and end, and have all the individual business JSON objects\n",
    "# separated by a comma\n",
    "data_json_str = \"[\" + ','.join(data) + \"]\"\n",
    "# now, load it into pandas\n",
    "data_df = pd.read_json(data_json_str)\n",
    "# business_category = pd.DataFrame([data_df['business_id'], data_df['categories']])\n",
    "business_category = data_df.ix[:,['business_id', 'categories']]\n",
    "# print business_category.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Restaurants', u'Nightlife', u'Food', u'Shopping']\n"
     ]
    }
   ],
   "source": [
    "business_time_category = business_attributes.merge(business_category, on = 'business_id', how = 'inner')\n",
    "business_categories = []\n",
    "business_category_count = {}\n",
    "for index, row in business_time_category.iterrows():\n",
    "    business_category_list = row['categories']\n",
    "#     print business_category_list\n",
    "    if business_category_list:\n",
    "        for category in business_category_list:\n",
    "            if category not in business_category_count:\n",
    "                business_category_count[category] = 0\n",
    "            else:\n",
    "                business_category_count[category] += 1\n",
    "for busi in business_category_count:\n",
    "    if business_category_count[busi] > 2000:\n",
    "        business_categories.append(busi)\n",
    "print business_categories\n",
    "business_time_category['in_categories'] = False\n",
    "for index, row in business_time_category.iterrows():\n",
    "    categories = row['categories']\n",
    "    if categories:\n",
    "        for category in categories:\n",
    "            if category in business_categories:\n",
    "                business_time_category.set_value(index, 'in_categories', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>Mon</th>\n",
       "      <th>Tue</th>\n",
       "      <th>Wed</th>\n",
       "      <th>Thu</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Sat</th>\n",
       "      <th>Sun</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>categories</th>\n",
       "      <th>in_categories</th>\n",
       "      <th>Restaurants</th>\n",
       "      <th>Nightlife</th>\n",
       "      <th>Food</th>\n",
       "      <th>Shopping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7KPBkxAOEtb3QeIL9PEErg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[Automotive, Convenience Stores, Food, Gas &amp; S...</td>\n",
       "      <td>True</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nhZ1HGWD8lMErdn3FuWuTQ</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[American (Traditional), Sports Bars, American...</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BH0K6SxPnY3wTRB7tA27hQ</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[Chinese, Restaurants]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dPxL6P_Gp74CqSPuL59Srg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[American (Traditional), Restaurants]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>HRIUU2Z4EsZBo59P0I2ZYA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>[Chicken Wings, Pizza, Italian, Restaurants]</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               business_id Mon Tue Wed Thu Fri Sat Sun  0  1   ...    20 21  \\\n",
       "0   7KPBkxAOEtb3QeIL9PEErg   1   1   1   2   1   3   1  2  1   ...     2  1   \n",
       "3   nhZ1HGWD8lMErdn3FuWuTQ   1   3   1   1   1   2   1  1  1   ...     1  1   \n",
       "6   BH0K6SxPnY3wTRB7tA27hQ   0   2   2   1   1   1   2  1  2   ...     0  0   \n",
       "7   dPxL6P_Gp74CqSPuL59Srg   1   1   1   1   1   1   1  1  0   ...     1  1   \n",
       "10  HRIUU2Z4EsZBo59P0I2ZYA   2   1   2   0   1   1   1  1  1   ...     1  0   \n",
       "\n",
       "   22 23                                         categories in_categories  \\\n",
       "0   1  1  [Automotive, Convenience Stores, Food, Gas & S...          True   \n",
       "3   1  3  [American (Traditional), Sports Bars, American...          True   \n",
       "6   1  2                             [Chinese, Restaurants]          True   \n",
       "7   1  1              [American (Traditional), Restaurants]          True   \n",
       "10  1  2       [Chicken Wings, Pizza, Italian, Restaurants]          True   \n",
       "\n",
       "   Restaurants Nightlife Food Shopping  \n",
       "0            0         0    1        0  \n",
       "3            1         1    0        0  \n",
       "6            1         0    0        0  \n",
       "7            1         0    0        0  \n",
       "10           1         0    0        0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "business_category_detail = business_time_category[business_time_category['in_categories'] == True]\n",
    "for category in business_categories:\n",
    "    business_category_detail[category] = 0\n",
    "for index, row in business_category_detail.iterrows():\n",
    "    categories = row['categories']\n",
    "    for category in categories:\n",
    "        if category in business_categories:\n",
    "            business_category_detail.set_value(index, category, 1)\n",
    "business_category_detail.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "time_distribution = business_category_detail.ix[:,1:32]\n",
    "is_restaurant = business_category_detail['Restaurants']\n",
    "clf = svm.SVC()\n",
    "clf.fit(time_distribution, is_restaurant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restaurants:  0.574535050072\n",
      "Nightlife:  0.836909871245\n",
      "Food:  0.780829756795\n",
      "Shopping:  0.788555078684\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "for category in business_categories:\n",
    "    components = [2, 5, 10, 15]\n",
    "    precision = 0\n",
    "    for n in components:\n",
    "        pca = PCA(n_components = n)\n",
    "        time_distribution = business_category_detail.ix[:,1:32]\n",
    "#         time_distribution = pca.fit(time_distribution)\n",
    "        is_restaurant = business_category_detail[category]\n",
    "        clf = svm.SVC()\n",
    "        train_data = time_distribution.ix[:15000, :]\n",
    "        train_data = pca.fit_transform(train_data)\n",
    "        train_target= is_restaurant.ix[:15000]\n",
    "        validation_data = time_distribution.ix[15000:, :]\n",
    "        validation_data = pca.fit_transform(validation_data)\n",
    "        validation_target = is_restaurant.ix[15000:].tolist()\n",
    "        # print train_target\n",
    "        # print len(validation_data)\n",
    "        clf.fit(train_data, train_target)\n",
    "        result = clf.predict(validation_data)\n",
    "        right_number, false_number = 0, 0\n",
    "        for i in range(len(result)):\n",
    "            if result[i] == validation_target[i]:\n",
    "                right_number += 1\n",
    "            else:\n",
    "                false_number += 1\n",
    "        if right_number/float(len(result)) > precision:\n",
    "            precision = right_number/float(len(result))\n",
    "    print category + \":  \" + str(precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "filename = \"yelp_academic_dataset_review.json\"\n",
    "with open(filename, 'rb') as f:\n",
    "    data = f.readlines()\n",
    "data = map(lambda x: x.rstrip(), data)\n",
    "data_json_str = \"[\" + ','.join(data) + \"]\"\n",
    "# now, load it into pandas\n",
    "data_df = pd.read_json(data_json_str, engine = 'python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                 user_id\n",
      "0  2aFiy99vNLklCx3T_tGS9A  KpkOkG6RIf4Ra25Lhhxf1A\n",
      "1  2aFiy99vNLklCx3T_tGS9A  bQ7fQq1otn9hKX-gXRsrgA\n",
      "2  2aFiy99vNLklCx3T_tGS9A  r1NUhdNmL6yU9Bn-Yx6FTw\n",
      "3  2LfIuF3_sX6uwe-IR-P0jQ  aW3ix1KNZAvoM8q-WghA3Q\n",
      "4  2LfIuF3_sX6uwe-IR-P0jQ  YOo-Cip8HqvKp_p9nEGphw\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "review_data = []\n",
    "review_data_dic = []\n",
    "count = 0\n",
    "filename = \"yelp_academic_dataset_review.json\"\n",
    "with open(filename, 'rb') as f:\n",
    "    for line in f:\n",
    "        review_data.append(line)\n",
    "        count += 1\n",
    "        if count == 1000000:\n",
    "            break\n",
    "for review in review_data:\n",
    "    review = json.loads(review)\n",
    "    review_info = {}\n",
    "    review_info['business_id'] = review['business_id']\n",
    "    review_info['user_id'] = review['user_id']\n",
    "    review_data_dic.append(review_info)\n",
    "review_data_pandas = pd.DataFrame(review_data_dic)\n",
    "print review_data_pandas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_review_count = {}\n",
    "for index, row in review_data_pandas.iterrows():\n",
    "    if row['user_id'] in user_review_count:\n",
    "        user_review_count[row['user_id']] += 1\n",
    "    else:\n",
    "        user_review_count[row['user_id']] = 1\n",
    "sort_user_review_counts = sorted(user_review_count.items(), key=lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_review_count = {}\n",
    "for index, row in review_data_pandas.iterrows():\n",
    "    if row['business_id'] in business_review_count:\n",
    "        business_review_count[row['business_id']] += 1\n",
    "    else:\n",
    "        business_review_count[row['business_id']] = 1\n",
    "sort_business_review_counts = sorted(business_review_count.items(), key=lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "business_user_count = {}\n",
    "for index, row in review_data_pandas.iterrows():\n",
    "    user_business = row['user_id'] + row['business_id']\n",
    "    if user_business in business_user_count:\n",
    "        business_user_count[user_business] += 1\n",
    "    else:\n",
    "        business_user_count[user_business] = 1\n",
    "sort_business_user_counts = sorted(business_user_count.items(), key=lambda x: x[1], reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frequent_users = [sort_user_review_counts[i][0] for i in range(5000)]\n",
    "# print frequent_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "business_users = {}\n",
    "frequent_users = [sort_user_review_counts[i][0] for i in range(5000)]\n",
    "for index, row in review_data_pandas.iterrows():\n",
    "    if row['user_id'] in frequent_users:\n",
    "        if row['business_id'] in business_users:\n",
    "            business_users[row['business_id']].append(row['user_id'])\n",
    "        else:\n",
    "            business_users[row['business_id']] = [row['user_id']]\n",
    "    else:\n",
    "        if row['business_id'] not in business_users:\n",
    "            business_users[row['business_id']] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              business_id                 user_id\n",
      "0  2aFiy99vNLklCx3T_tGS9A  KpkOkG6RIf4Ra25Lhhxf1A\n",
      "1  2aFiy99vNLklCx3T_tGS9A  bQ7fQq1otn9hKX-gXRsrgA\n",
      "2  2aFiy99vNLklCx3T_tGS9A  r1NUhdNmL6yU9Bn-Yx6FTw\n",
      "3  2LfIuF3_sX6uwe-IR-P0jQ  aW3ix1KNZAvoM8q-WghA3Q\n",
      "4  2LfIuF3_sX6uwe-IR-P0jQ  YOo-Cip8HqvKp_p9nEGphw\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "review_data = []\n",
    "review_data_dic = []\n",
    "count = 0\n",
    "filename = \"yelp_academic_dataset_review.json\"\n",
    "with open(filename, 'rb') as f:\n",
    "    for line in f:\n",
    "        review_data.append(line)\n",
    "        count += 1\n",
    "        if count == 1000000:\n",
    "            break\n",
    "for review in review_data:\n",
    "    review = json.loads(review)\n",
    "    review_info = {}\n",
    "    review_info['business_id'] = review['business_id']\n",
    "    review_info['user_id'] = review['user_id']\n",
    "    review_data_dic.append(review_info)\n",
    "review_data_pandas = pd.DataFrame(review_data_dic)\n",
    "print review_data_pandas.head()\n",
    "\n",
    "user_review_count = {}\n",
    "for index, row in review_data_pandas.iterrows():\n",
    "    if row['user_id'] in user_review_count:\n",
    "        user_review_count[row['user_id']] += 1\n",
    "    else:\n",
    "        user_review_count[row['user_id']] = 1\n",
    "sort_user_review_counts = sorted(user_review_count.items(), key=lambda x: x[1], reverse = True)\n",
    "\n",
    "business_review_count = {}\n",
    "for index, row in review_data_pandas.iterrows():\n",
    "    if row['business_id'] in business_review_count:\n",
    "        business_review_count[row['business_id']] += 1\n",
    "    else:\n",
    "        business_review_count[row['business_id']] = 1\n",
    "sort_business_review_counts = sorted(business_review_count.items(), key=lambda x: x[1], reverse = True)\n",
    "\n",
    "business_user_count = {}\n",
    "for index, row in review_data_pandas.iterrows():\n",
    "    user_business = row['user_id'] + row['business_id']\n",
    "    if user_business in business_user_count:\n",
    "        business_user_count[user_business] += 1\n",
    "    else:\n",
    "        business_user_count[user_business] = 1\n",
    "sort_business_user_counts = sorted(business_user_count.items(), key=lambda x: x[1], reverse = True)\n",
    "\n",
    "frequent_users = [sort_user_review_counts[i][0] for i in range(5000)]\n",
    "\n",
    "business_users = {}\n",
    "frequent_users = [sort_user_review_counts[i][0] for i in range(5000)]\n",
    "for index, row in review_data_pandas.iterrows():\n",
    "    if row['user_id'] in frequent_users:\n",
    "        if row['business_id'] in business_users:\n",
    "            business_users[row['business_id']].append(row['user_id'])\n",
    "        else:\n",
    "            business_users[row['business_id']] = [row['user_id']]\n",
    "    else:\n",
    "        if row['business_id'] not in business_users:\n",
    "            business_users[row['business_id']] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.savetxt(r'business_user_review_network_5000', df.values, fmt='%d')\n",
    "business_user_review_network.to_pickle('business_user_review_network_5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "business_users_info = pd.read_pickle('business_user_review_network_5000')\n",
    "filename = \"yelp_academic_dataset_business.json\"\n",
    "with open(filename, 'rb') as f:\n",
    "    data = f.readlines()\n",
    "\n",
    "data = map(lambda x: x.rstrip(), data)\n",
    "\n",
    "data_json_str = \"[\" + ','.join(data) + \"]\"\n",
    "data_df = pd.read_json(data_json_str)\n",
    "business_category = data_df.ix[:,['business_id', 'categories']]\n",
    "\n",
    "business_users_category = business_users_info.merge(business_category, how = 'inner')\n",
    "\n",
    "category_count = {}\n",
    "for index, busi in business_users_category.iterrows():\n",
    "    categories = busi['categories']\n",
    "    for category in categories:\n",
    "        if category in category_count:\n",
    "            category_count[category] += 1\n",
    "        else:\n",
    "            category_count[category] = 1\n",
    "sort_business_category_counts = sorted(category_count.items(), key=lambda x: x[1], reverse = True)\n",
    "\n",
    "frequent_category_list = [item[0] for item in sort_business_category_counts[:4]]\n",
    "\n",
    "for category in frequent_category_list:\n",
    "    business_users_category[category] = False\n",
    "    \n",
    "for index in range(5000):\n",
    "    row = business_users_category.iloc[[index]]\n",
    "    categories = row['categories'].tolist()\n",
    "    for category in categories[0]:\n",
    "        if category in frequent_category_list:\n",
    "            business_users_category.set_value(index, category, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "356\n",
      "Presision for Restaurants is 0.71 .\n",
      "387\n",
      "388\n",
      "391\n",
      "Presision for Food is 0.78 .\n",
      "398\n",
      "399\n",
      "401\n",
      "Presision for Nightlife is 0.80 .\n",
      "409\n",
      "410\n",
      "411\n",
      "Presision for Bars is 0.82 .\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "for busi in frequent_category_list:\n",
    "    maxPrecision = 0\n",
    "    for n in [5, 20, 50, 100]:\n",
    "        for k in [5, 10, 20, 50]:\n",
    "            pca = PCA(n_components = n)\n",
    "            knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "            train_x = pca.fit_transform(business_users_category.ix[:4500, 1:5000])\n",
    "            train_y = business_users_category.ix[:4500][busi].tolist()\n",
    "            test_x = pca.fit_transform(business_users_category.ix[500:,1:5000])\n",
    "            test_y = business_users_category.ix[500:][busi].tolist()\n",
    "            knn.fit(train_x, train_y)\n",
    "            # print train_y\n",
    "            predictions = knn.predict(test_x)\n",
    "            right_count = 0\n",
    "            for i in range(500):\n",
    "                if predictions[i] == test_y[i]:\n",
    "                    right_count += 1\n",
    "            if right_count / 500.0 > maxPrecision:\n",
    "                maxPrecision = right_count / 500.0\n",
    "                print right_count\n",
    "    print \"Presision for %s is %.2f .\" %(busi, maxPrecision)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
